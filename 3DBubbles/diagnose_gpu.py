#!/usr/bin/env python3
# diagnose_gpu.py
"""
GPUè¯Šæ–­è„šæœ¬ - å…¨é¢è¯Šæ–­3DBubbles_v2.0çš„GPUä½¿ç”¨æƒ…å†µ

ä½¿ç”¨æ–¹æ³•:
python diagnose_gpu.py [--detailed] [--stress-test] [--fix-issues]
"""

import os
import sys
import time
import argparse
import subprocess
from typing import Dict, List, Any

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'modules'))

def check_system_environment():
    """æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ"""
    print("=== ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥ ===")
    
    # æ£€æŸ¥NVIDIAé©±åŠ¨
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIAé©±åŠ¨æ­£å¸¸")
            lines = result.stdout.split('\n')
            for line in lines:
                if 'Driver Version:' in line:
                    driver_version = line.split('Driver Version:')[1].split()[0]
                    print(f"   é©±åŠ¨ç‰ˆæœ¬: {driver_version}")
                if 'CUDA Version:' in line:
                    cuda_version = line.split('CUDA Version:')[1].split()[0]
                    print(f"   CUDAç‰ˆæœ¬: {cuda_version}")
        else:
            print("âŒ NVIDIAé©±åŠ¨æ£€æŸ¥å¤±è´¥")
            return False
    except FileNotFoundError:
        print("âŒ nvidia-smiå‘½ä»¤æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥NVIDIAé©±åŠ¨å®‰è£…")
        return False
    
    # æ£€æŸ¥PyTorch
    try:
        import torch
        print("âœ… PyTorchå·²å®‰è£…")
        print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                name = torch.cuda.get_device_name(i)
                props = torch.cuda.get_device_properties(i)
                memory_gb = props.total_memory / 1024**3
                print(f"   GPU {i}: {name} ({memory_gb:.1f}GB)")
        return True
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        return False


def check_kornia():
    """æ£€æŸ¥Korniaåº“"""
    print("\n=== Korniaåº“æ£€æŸ¥ ===")
    try:
        import kornia
        print("âœ… Korniaå·²å®‰è£…")
        print(f"   Korniaç‰ˆæœ¬: {kornia.__version__}")
        
        # æµ‹è¯•Kornia GPUåŠŸèƒ½
        import torch
        if torch.cuda.is_available():
            try:
                x = torch.randn(1, 3, 64, 64, device='cuda:0')
                edges = kornia.filters.canny(x, low_threshold=0.1, high_threshold=0.2)
                print("âœ… Kornia GPUåŠŸèƒ½æ­£å¸¸")
                del x, edges
                torch.cuda.empty_cache()
            except Exception as e:
                print(f"âŒ Kornia GPUåŠŸèƒ½å¼‚å¸¸: {e}")
        return True
    except ImportError:
        print("âŒ Korniaæœªå®‰è£…")
        return False


def test_gpu_managers():
    """æµ‹è¯•GPUç®¡ç†å™¨"""
    print("\n=== GPUç®¡ç†å™¨æµ‹è¯• ===")
    
    try:
        from modules.gpu_manager import get_global_gpu_manager
        from modules.gpu_performance_manager import get_global_performance_manager
        
        # æµ‹è¯•GPUç®¡ç†å™¨
        print("æµ‹è¯•GPUç®¡ç†å™¨...")
        gpu_manager = get_global_gpu_manager()
        print(f"âœ… GPUç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"   å¯ç”¨GPU: {gpu_manager.available_gpus}")
        print(f"   ä½¿ç”¨GPU: {gpu_manager.gpu_ids}")
        print(f"   GPUæ•°é‡: {gpu_manager.num_gpus}")
        print(f"   å¯ç”¨GPU: {gpu_manager.use_gpu}")
        
        # æµ‹è¯•æ€§èƒ½ç®¡ç†å™¨
        print("æµ‹è¯•æ€§èƒ½ç®¡ç†å™¨...")
        perf_manager = get_global_performance_manager()
        print(f"âœ… æ€§èƒ½ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"   åº”è¯¥ä½¿ç”¨GPU: {perf_manager.should_use_gpu()}")
        
        return True
    except Exception as e:
        print(f"âŒ GPUç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_gpu_analysis_functions():
    """æµ‹è¯•GPUåˆ†æå‡½æ•°"""
    print("\n=== GPUåˆ†æå‡½æ•°æµ‹è¯• ===")
    
    try:
        import numpy as np
        import cv2
        from modules.bubble_analysis import (
            analyze_bubble_image_from_array,
            analyze_bubble_image_from_array_gpu,
            analyze_bubble_image_from_array_smart,
            get_analysis_performance_report,
            reset_analysis_performance
        )
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        print("åˆ›å»ºæµ‹è¯•å›¾åƒ...")
        img = np.ones((128, 128, 3), dtype=np.uint8) * 255
        center = (64, 64)
        axes = (30, 20)
        angle = 45
        cv2.ellipse(img, center, axes, angle, 0, 360, (100, 100, 100), -1)
        
        # é‡ç½®æ€§èƒ½ç»Ÿè®¡
        reset_analysis_performance()
        
        # æµ‹è¯•CPUåˆ†æ
        print("æµ‹è¯•CPUåˆ†æ...")
        start_time = time.time()
        cpu_result = analyze_bubble_image_from_array(img)
        cpu_time = time.time() - start_time
        print(f"   CPUåˆ†ææ—¶é—´: {cpu_time:.4f}s")
        print(f"   CPUç»“æœ: {'æˆåŠŸ' if cpu_result else 'å¤±è´¥'}")
        
        # æµ‹è¯•GPUåˆ†æ
        print("æµ‹è¯•GPUåˆ†æ...")
        start_time = time.time()
        gpu_result = analyze_bubble_image_from_array_gpu(img, device='cuda:0')
        gpu_time = time.time() - start_time
        print(f"   GPUåˆ†ææ—¶é—´: {gpu_time:.4f}s")
        print(f"   GPUç»“æœ: {'æˆåŠŸ' if gpu_result else 'å¤±è´¥'}")
        
        # æµ‹è¯•æ™ºèƒ½åˆ†æ
        print("æµ‹è¯•æ™ºèƒ½åˆ†æ...")
        start_time = time.time()
        smart_result = analyze_bubble_image_from_array_smart(img)
        smart_time = time.time() - start_time
        print(f"   æ™ºèƒ½åˆ†ææ—¶é—´: {smart_time:.4f}s")
        print(f"   æ™ºèƒ½ç»“æœ: {'æˆåŠŸ' if smart_result else 'å¤±è´¥'}")
        
        # æ€§èƒ½æŠ¥å‘Š
        print("æ€§èƒ½æŠ¥å‘Š:")
        report = get_analysis_performance_report()
        for key, value in report.items():
            print(f"   {key}: {value}")
        
        # åŠ é€Ÿæ¯”è®¡ç®—
        if gpu_time > 0 and cpu_time > 0:
            speedup = cpu_time / gpu_time
            print(f"   GPUåŠ é€Ÿæ¯”: {speedup:.2f}x")
        
        return True
    except Exception as e:
        print(f"âŒ GPUåˆ†æå‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def monitor_gpu_during_operation():
    """åœ¨æ“ä½œæœŸé—´ç›‘æ§GPUä½¿ç”¨æƒ…å†µ"""
    print("\n=== GPUä½¿ç”¨ç›‘æ§æµ‹è¯• ===")
    
    try:
        import torch
        from gpu_monitoring_patch import GPUUsageTracker
        
        print("æ‰§è¡ŒGPUå¯†é›†å‹æ“ä½œå¹¶ç›‘æ§...")
        
        with GPUUsageTracker("GPUå¯†é›†å‹æµ‹è¯•", device_id=0, verbose=True):
            # æ‰§è¡Œä¸€äº›GPUæ“ä½œ
            device = torch.device('cuda:0')
            
            # åˆ›å»ºå¤§é‡å¼ é‡è¿›è¡Œè®¡ç®—
            tensors = []
            for i in range(10):
                a = torch.randn(500, 500, device=device)
                b = torch.randn(500, 500, device=device)
                c = torch.matmul(a, b)
                tensors.append(c)
                time.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿä»¥ä¾¿è§‚å¯Ÿ
            
            # æ¸…ç†
            del tensors
            torch.cuda.empty_cache()
        
        return True
    except Exception as e:
        print(f"âŒ GPUç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        return False


def stress_test_gpu():
    """GPUå‹åŠ›æµ‹è¯•"""
    print("\n=== GPUå‹åŠ›æµ‹è¯• ===")
    
    try:
        from gpu_monitoring_patch import stress_test_gpu
        stress_test_gpu(device_id=0, duration=5.0)
        return True
    except Exception as e:
        print(f"âŒ GPUå‹åŠ›æµ‹è¯•å¤±è´¥: {e}")
        return False


def provide_optimization_recommendations():
    """æä¾›ä¼˜åŒ–å»ºè®®"""
    print("\n=== ä¼˜åŒ–å»ºè®® ===")
    
    try:
        from gpu_optimization_config import GPUOptimizationConfig, get_optimized_gpu_args
        
        # æ‰“å°ä¼˜åŒ–æŠ¥å‘Š
        GPUOptimizationConfig.print_optimization_report()
        
        # æ¨èå¯åŠ¨å‚æ•°
        print("\næ¨èçš„FlowRenderer.pyå¯åŠ¨å‚æ•°:")
        args = get_optimized_gpu_args()
        cmd_args = []
        for key, value in args.items():
            if key != 'gpu_memory_fraction':  # è¿™ä¸ªå‚æ•°ä¸æ˜¯å‘½ä»¤è¡Œå‚æ•°
                cmd_args.append(f"--{key.replace('_', '-')} {value}")
        
        print(f"python FlowRenderer.py {' '.join(cmd_args)}")
        
        return True
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–å»ºè®®ç”Ÿæˆå¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='3DBubbles GPUè¯Šæ–­å·¥å…·')
    parser.add_argument('--detailed', action='store_true', help='è¯¦ç»†è¯Šæ–­')
    parser.add_argument('--stress-test', action='store_true', help='æ‰§è¡ŒGPUå‹åŠ›æµ‹è¯•')
    parser.add_argument('--fix-issues', action='store_true', help='å°è¯•ä¿®å¤å‘ç°çš„é—®é¢˜')
    
    args = parser.parse_args()
    
    print("3DBubbles_v2.0 GPUè¯Šæ–­å·¥å…·")
    print("=" * 50)
    
    # åŸºç¡€æ£€æŸ¥
    results = []
    results.append(("ç³»ç»Ÿç¯å¢ƒ", check_system_environment()))
    results.append(("Korniaåº“", check_kornia()))
    results.append(("GPUç®¡ç†å™¨", test_gpu_managers()))
    results.append(("GPUåˆ†æå‡½æ•°", test_gpu_analysis_functions()))
    
    if args.detailed:
        results.append(("GPUä½¿ç”¨ç›‘æ§", monitor_gpu_during_operation()))
    
    if args.stress_test:
        results.append(("GPUå‹åŠ›æµ‹è¯•", stress_test_gpu()))
    
    # ä¼˜åŒ–å»ºè®®
    provide_optimization_recommendations()
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("è¯Šæ–­ç»“æœæ€»ç»“:")
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼GPUåŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
        print("\nå¦‚æœæ‚¨è§‰å¾—GPUåˆ©ç”¨ç‡ä¸é«˜ï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºï¼š")
        print("1. å½“å‰ä»»åŠ¡çš„GPUè®¡ç®—éƒ¨åˆ†å æ¯”è¾ƒå°")
        print("2. GPUæ“ä½œæ—¶é—´å¾ˆçŸ­ï¼Œnvidia-smiå¯èƒ½æ•æ‰ä¸åˆ°")
        print("3. ä¸»è¦ç“¶é¢ˆåœ¨CPUå¯†é›†å‹çš„æ•°æ®ç­›é€‰æ“ä½œä¸Š")
    else:
        print("âš ï¸  å‘ç°é—®é¢˜ï¼Œè¯·æ ¹æ®ä¸Šè¿°é”™è¯¯ä¿¡æ¯è¿›è¡Œä¿®å¤ã€‚")
    
    return passed == total


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
